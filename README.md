# Optimization Algorithms Benchmark Suite
[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
Official implementation of optimization algorithms from the paper: 
**"AdaPID: Adaptive Momentum Gradient Method based on PID Controller for Non-Convex Stochastic Optimization in Deep Learning"**
*Ailun Jian, Xun Li, Weigang Sun, Gaohang Yu* 

# Execute Rastrigin function optimization
python main.py --function rastrigin --optimizer AdaPID

# Citation
@article{yourpaper2024,
  title={Your Paper Title},
  author={Your Name et al.},
  journal={Journal Name},
  year={2024},
  doi={your-doi-here}
}
